{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99468e3-e6bf-49c3-aa91-dfefc455ffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• wrote raw → SYNTH_RAW_DATA.csv\n",
      "• wrote PCA → SYNTH_PCA_DATA.csv\n",
      "• wrote PCA → SYNTH_PCA_DATA.csv\n"
     ]
    }
   ],
   "source": [
    "# Credit Card Fraud Detection Predictive Models\n",
    "# Synthetic Data Generator and PCA Transformation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_synthetic_demo(\n",
    "    n_samples: int = 100_000,\n",
    "    random_state: int = 42,\n",
    "    raw_out: str = \"SYNTH_RAW_DATA.csv\",\n",
    "    pca_out: str = \"SYNTH_PCA_DATA.csv\",\n",
    "):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # 1) COMMON SETUP\n",
    "    n_latent = 5\n",
    "    Z = np.random.normal(0, 1, size=(n_samples, n_latent))\n",
    "    times = np.random.choice(np.arange(0, 172_800, dtype=int),\n",
    "                             size=n_samples, replace=True)\n",
    "    times.sort()\n",
    "    Hour = (times // 3600) % 24\n",
    "\n",
    "    # 2) NUMERIC FEATURES WITH CORRELATION\n",
    "    numeric_cols = [\n",
    "        \"Amount\", \"Age\", \"Tenure\", \"MerchantRisk\", \"DeviceTrust\",\n",
    "        \"Txn24h\", \"Avg30d\", \"IPReputation\", \"Latitude\", \"Longitude\", \"DistFromHome\"\n",
    "    ]\n",
    "    loadings = np.random.uniform(-1, 1, size=(n_latent, len(numeric_cols)))\n",
    "    num_data = Z.dot(loadings) + np.random.normal(0, 0.5, size=(n_samples, len(numeric_cols)))\n",
    "    df_num = pd.DataFrame(num_data, columns=numeric_cols)\n",
    "    df_num[\"Amount\"]    = np.exp(df_num[\"Amount\"] * 0.5 + 3.5)\n",
    "    df_num[\"Age\"]       = np.clip(df_num[\"Age\"] * 5 + 40, 18, 90)\n",
    "    df_num[\"Tenure\"]    = np.abs(df_num[\"Tenure\"] * 10).astype(int)\n",
    "    df_num[\"Txn24h\"]    = np.abs(df_num[\"Txn24h\"].round()).astype(int)\n",
    "    df_num[\"Latitude\"]  = np.clip(37 + df_num[\"Latitude\"]*5, 25, 50)\n",
    "    df_num[\"Longitude\"] = np.clip(-95 + df_num[\"Longitude\"]*10, -125, -67)\n",
    "\n",
    "    # 3) CATEGORICAL FEATURES\n",
    "    cats = {\n",
    "        \"TxType\":     ([\"purchase\",\"withdrawal\",\"transfer\",\"payment\"], [0.7,0.1,0.1,0.1]),\n",
    "        \"DeviceType\": ([\"mobile\",\"desktop\",\"ATM\",\"POS\",\"web\"],         [0.5,0.2,0.05,0.2,0.05]),\n",
    "        \"MerchantCat\":([\n",
    "            \"grocery\",\"electronics\",\"travel\",\"entertainment\",\"gas\",\n",
    "            \"restaurant\",\"utilities\",\"clothing\"],[1/8]*8),\n",
    "        \"Channel\":    ([\"online\",\"in-store\",\"contactless\",\"chip\"],      [0.4,0.4,0.1,0.1]),\n",
    "    }\n",
    "    df_cat = pd.DataFrame({\n",
    "        col: np.random.choice(domain, size=n_samples, p=probs)\n",
    "             if isinstance(probs, list)\n",
    "             else np.random.choice(domain, size=n_samples)\n",
    "        for col, (domain, probs) in cats.items()\n",
    "    })\n",
    "\n",
    "    # 4) COMBINE & ADD TIME/CardPresent\n",
    "    raw = pd.concat([\n",
    "        pd.Series(times, name=\"Time\"),\n",
    "        df_num.reset_index(drop=True),\n",
    "        pd.Series(Hour, name=\"Hour\"),\n",
    "        df_cat,\n",
    "    ], axis=1)\n",
    "    raw[\"CardPresent\"] = (np.random.rand(n_samples) < 0.7).astype(int)\n",
    "\n",
    "    # 5) RE-INTRODUCE MISSINGNESS\n",
    "    missing_rates = {\n",
    "        \"Amount\": 0.01, \"Age\": 0.01, \"MerchantRisk\": 0.01, \"DeviceTrust\": 0.01,\n",
    "        \"Txn24h\": 0.01, \"Avg30d\": 0.01, \"IPReputation\": 0.01,\n",
    "        \"Latitude\": 0.005, \"Longitude\": 0.005, \"DistFromHome\": 0.01,\n",
    "        \"TxType\": 0.005, \"DeviceType\": 0.005, \"MerchantCat\": 0.01, \"Channel\": 0.005,\n",
    "    }\n",
    "    for col, rate in missing_rates.items():\n",
    "        mask = np.random.rand(n_samples) < rate\n",
    "        raw.loc[mask, col] = np.nan\n",
    "\n",
    "    # 6) ADD MEASUREMENT NOISE (reduced)\n",
    "    noise_cols = [\n",
    "        \"Amount\",\"Age\",\"MerchantRisk\",\"DeviceTrust\",\n",
    "        \"Txn24h\",\"Avg30d\",\"IPReputation\",\n",
    "        \"Latitude\",\"Longitude\",\"DistFromHome\"\n",
    "    ]\n",
    "    for c in noise_cols:\n",
    "        nonnull = raw[c].dropna()\n",
    "        if nonnull.empty:\n",
    "            continue\n",
    "        sigma = nonnull.std() * 0.005  # much less noise\n",
    "        raw.loc[raw[c].notna(), c] += np.random.normal(0, sigma, size=len(nonnull))\n",
    "\n",
    "    # 7) SIMULATE FRAUD LABEL - STRONG DEPENDENCE ON NUMERICS & CATEGORICALS\n",
    "    fraud_signal = (\n",
    "        9.0 * (raw[\"Amount\"] > 2000).astype(float) +\n",
    "        2.0 * (raw[\"CardPresent\"] == 0).astype(float) +\n",
    "        2.0 * (raw[\"MerchantRisk\"] > 3.0).astype(float) +\n",
    "        1.5 * (raw[\"DeviceType\"] == \"web\").astype(float) +\n",
    "        1.5 * (raw[\"Channel\"] == \"online\").astype(float) +\n",
    "        1.0 * (raw[\"TxType\"] == \"withdrawal\").astype(float) +\n",
    "        1.0 * (raw[\"Hour\"].isin([0,1,2,3,4,23])).astype(float) +\n",
    "        1.0 * (raw[\"Txn24h\"] > 10).astype(float) +\n",
    "        1.0 * (raw[\"IPReputation\"] > 2.0).astype(float)\n",
    "    )\n",
    "    # Add tiny noise\n",
    "    fraud_signal += np.random.normal(0, 0.01, size=n_samples)\n",
    "    fraud_prob = 1 / (1 + np.exp(-fraud_signal))\n",
    "    raw[\"Class\"] = (np.random.rand(n_samples) < fraud_prob).astype(int)\n",
    "\n",
    "    raw.to_csv(raw_out, index=False)\n",
    "    print(f\"• wrote raw → {raw_out}\")\n",
    "\n",
    "    # 8) PCA TRANSFORM (NUMERIC + OHE CATEGORICALS)\n",
    "    cat_cols = [\"TxType\", \"DeviceType\", \"MerchantCat\", \"Channel\", \"CardPresent\"]\n",
    "    num = raw[numeric_cols].fillna(raw[numeric_cols].mean())\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    cat_mat = ohe.fit_transform(raw[cat_cols].fillna(\"MISSING\"))\n",
    "    features = np.concatenate([num.values, cat_mat], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(features)\n",
    "    pca = PCA(n_components=28, random_state=random_state)\n",
    "    PCs = pca.fit_transform(Xs)\n",
    "    pca_df = pd.DataFrame(PCs, columns=[f\"V{i+1}\" for i in range(28)])\n",
    "    pca_df[\"Time\"]   = raw[\"Time\"].astype(int)\n",
    "    pca_df[\"Amount\"] = raw[\"Amount\"]\n",
    "    pca_df[\"Class\"]  = raw[\"Class\"]\n",
    "    pca_df.to_csv(pca_out, index=False)\n",
    "    print(f\"• wrote PCA → {pca_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_synthetic_demo(\n",
    "        n_samples=478_324,\n",
    "        raw_out=\"SYNTH_RAW_DATA.csv\",\n",
    "        pca_out=\"SYNTH_PCA_DATA.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9916d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
