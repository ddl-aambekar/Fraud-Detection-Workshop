{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf2b1218-f752-4e49-b0f6-95f2ac8b8323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loaded 478,324 rows from raw_cc_transactions.csv\n",
      "üßπ Dropped 64,997 rows with missing data\n",
      "‚úÖ Wrote 413,327 rows to: cleaned_cc_transactions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 18:59:25 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c5c54204d24c708dbac284cf494851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|‚ñå         | 1/19 [00:01<00:20,  1.16s/it]\u001b[A\n",
      " 11%|‚ñà         | 2/19 [00:02<00:16,  1.02it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 3/19 [00:02<00:11,  1.42it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà        | 4/19 [00:02<00:06,  2.15it/s]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:03<00:00,  6.08it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b5d7708b8940d188dc2c578bb01c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a5171b83754fd990e1917a65b8532d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f57cc68d48c4f748c02a50e17a93771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run PCA Pipeline at: http://127.0.0.1:8768/#/experiments/1537/runs/71a47a53d096430b9487dd2ca8910159\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1537\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion, Processing, and MLflow Model Logging\n",
    "import io, os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from domino.data_sources import DataSourceClient\n",
    "from domino_data.datasets import DatasetClient\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "domino_working_dir = os.environ.get(\"DOMINO_WORKING_DIR\", \".\")\n",
    "domino_datasource_dir = domino_working_dir.replace('code', 'data')\n",
    "domino_artifact_dir = domino_working_dir.replace('code', 'artifacts')\n",
    "domino_project_name = os.environ.get(\"DOMINO_PROJECT_NAME\", \"my-local-project\")\n",
    "\n",
    "## Data Ingestion, Processing, and MLflow Model Logging\n",
    "\n",
    "def run_data_ingestion_and_processing(raw_filename: str, pca_filename: str, n_components: int = 28):\n",
    "    # 1) Download the raw file\n",
    "    ds = DataSourceClient().get_datasource(\"credit_card_fraud_detection\")\n",
    "    buf = io.BytesIO()\n",
    "    ds.download_fileobj(raw_filename, buf)\n",
    "    buf.seek(0)\n",
    "    df = pd.read_csv(buf)\n",
    "    print(f\"üîç Loaded {len(df):,} rows from {raw_filename}\")\n",
    "\n",
    "    # 2) Drop missing rows\n",
    "    before = len(df)\n",
    "    df = df.dropna()\n",
    "    print(f\"üßπ Dropped {before - len(df):,} rows with missing data\")\n",
    "\n",
    "    # 3) Define columns\n",
    "    cat_cols = [\"TxType\", \"DeviceType\", \"MerchantCat\", \"Channel\"]\n",
    "    num_cols = [c for c in df.columns if c not in cat_cols + [\"Class\"]]\n",
    "    X = df[cat_cols + num_cols]\n",
    "    y = df[\"Class\"]\n",
    "\n",
    "    # 4) Build and fit Pipeline: OHE -> Scale -> PCA\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"scale\", StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"pca\",     PCA(n_components=n_components, random_state=0))\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline and get PCs\n",
    "    PCs = pipeline.fit_transform(X)\n",
    "    pca_model = pipeline.named_steps[\"pca\"]\n",
    "\n",
    "    # 5) Reassemble and save PCA DataFrame\n",
    "    pca_df = pd.DataFrame(PCs, columns=[f\"V{i+1}\" for i in range(n_components)])\n",
    "    pca_df[\"Time\"]   = df[\"Time\"].astype(int)\n",
    "    pca_df[\"Amount\"] = df[\"Amount\"]\n",
    "    pca_df[\"Class\"]  = df[\"Class\"].astype(int)\n",
    "\n",
    "    full_path = f\"{domino_datasource_dir}/{domino_project_name}/{pca_filename}\"\n",
    "    pca_df.to_csv(full_path, index=False)\n",
    "    print(f\"‚úÖ Wrote {len(pca_df):,} rows to: {pca_filename}\")\n",
    "\n",
    "    # 6) Start MLflow run and log everything\n",
    "    mlflow.set_experiment('CC Fraud PCA Training [testing]')\n",
    "    with mlflow.start_run(run_name=\"PCA Pipeline\") as run:\n",
    "        mlflow.log_param(\"n_components\", n_components)\n",
    "        mlflow.log_param(\"raw_filename\", raw_filename)\n",
    "        mlflow.log_param(\"pca_filename\", pca_filename)\n",
    "        mlflow.log_param(\"num_rows_loaded\", before)\n",
    "        mlflow.log_param(\"num_rows_after_dropna\", len(df))\n",
    "        mlflow.log_param(\"num_cat_features\", len(cat_cols))\n",
    "        mlflow.log_param(\"num_num_features\", len(num_cols))\n",
    "\n",
    "        # Log the PCA CSV\n",
    "        mlflow.log_artifact(full_path, artifact_path=\"data\")\n",
    "\n",
    "                # Log the pipeline as a single model\n",
    "        # Ensure numeric columns are float64 for signature\n",
    "        X_sig = X.copy()\n",
    "        for col in num_cols:\n",
    "            if np.issubdtype(X_sig[col].dtype, np.integer):\n",
    "                X_sig[col] = X_sig[col].astype(\"float64\")\n",
    "        signature = infer_signature(X_sig.iloc[:5], pipeline.transform(X_sig.iloc[:5]))\n",
    "        mlflow.sklearn.log_model(\n",
    "            pipeline,\n",
    "            artifact_path=\"preproc_pca_pipeline\",\n",
    "            signature=signature\n",
    "        )\n",
    "        mlflow.set_tag(\"pipeline\", \"full_preproc_pca\")\n",
    "\n",
    "        # 7) Generate and log artifacts (corr, scatter, scree, etc.)\n",
    "        num_df = df.select_dtypes(include=\"number\").drop(columns=[\"Time\", \"Class\"], errors=\"ignore\")\n",
    "        # Correlation heatmap\n",
    "        plt.figure(figsize=(14,12))\n",
    "        sns.heatmap(num_df.corr(), annot=True, fmt=\".2f\", cmap=\"vlag\")\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        corr_path = f\"{domino_artifact_dir}/raw_correlation_matrix.png\"\n",
    "        plt.savefig(corr_path); plt.close()\n",
    "        mlflow.log_artifact(corr_path, artifact_path=\"plots\")\n",
    "        # Scatter matrix\n",
    "        sample_df = num_df.sample(n=500, random_state=0)\n",
    "        fig = scatter_matrix(sample_df, alpha=0.2, diagonal=\"hist\", figsize=(15,15))\n",
    "        scatter_path = f\"{domino_artifact_dir}/raw_scatter_plots.png\"\n",
    "        plt.savefig(scatter_path); plt.close()\n",
    "        mlflow.log_artifact(scatter_path, artifact_path=\"plots\")\n",
    "        # Scree and cumulative\n",
    "        evr = pca_model.explained_variance_ratio_\n",
    "        pcs = np.arange(1, len(evr)+1)\n",
    "        # Scree\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pcs, evr, marker='o')\n",
    "        plt.xlabel(\"PC\"); plt.ylabel(\"Explained Var Ratio\"); plt.title(\"Scree Plot\")\n",
    "        scree_path = f\"{domino_artifact_dir}/pca_scree.png\"\n",
    "        plt.savefig(scree_path); plt.close()\n",
    "        mlflow.log_artifact(scree_path, artifact_path=\"plots\")\n",
    "        # Cumulative\n",
    "        cumvar = np.cumsum(evr)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pcs, cumvar, marker='o')\n",
    "        plt.axhline(0.9, linestyle='--', label='90%')\n",
    "        plt.xlabel(\"# Components\"); plt.ylabel(\"Cumulative Var\"); plt.title(\"Cumulative Variance\")\n",
    "        plt.legend()\n",
    "        cumvar_path = f\"{domino_artifact_dir}/pca_cumulative_variance.png\"\n",
    "        plt.savefig(cumvar_path); plt.close()\n",
    "        mlflow.log_artifact(cumvar_path, artifact_path=\"plots\")\n",
    "\n",
    "        # 8) EDA HTML\n",
    "        profile = ProfileReport(df, title=\"EDA Report\", explorative=True, minimal=True)\n",
    "        eda_path = f\"{domino_artifact_dir}/eda_report.html\"\n",
    "        profile.to_file(eda_path)\n",
    "        mlflow.log_artifact(eda_path, artifact_path=\"eda\")\n",
    "\n",
    "    return df, pca_df\n",
    "\n",
    "# Usage:\n",
    "raw_df, pca_df = run_data_ingestion_and_processing(\n",
    "    raw_filename=\"raw_cc_transactions.csv\",\n",
    "    pca_filename=\"cleaned_cc_transactions.csv\",\n",
    "    n_components=28\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99468e3-e6bf-49c3-aa91-dfefc455ffd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731edc8-57c3-4269-bce7-1616a02191ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
