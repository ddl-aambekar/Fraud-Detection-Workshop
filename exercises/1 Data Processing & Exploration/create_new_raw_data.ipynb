{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99468e3-e6bf-49c3-aa91-dfefc455ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_synthetic_demo(\n",
    "    n_samples: int = 100_000,\n",
    "    random_state: int = 42,\n",
    "    raw_out: str = \"SYNTH_RAW_DATA.csv\",\n",
    "    pca_out: str = \"SYNTH_PCA_DATA.csv\",\n",
    "):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # ─── 1) COMMON SETUP ───────────────────────────────────────────────\n",
    "    # A few latent factors (e.g. underlying fraud drivers)\n",
    "    n_latent = 5\n",
    "    Z = np.random.normal(0, 1, size=(n_samples, n_latent))\n",
    "\n",
    "    # Time feature, sorted so it still makes sense as a timestamp\n",
    "    times = np.random.choice(np.arange(0, 172_800, dtype=int),\n",
    "                             size=n_samples, replace=True)\n",
    "    times.sort()\n",
    "    Hour = (times // 3600) % 24\n",
    "\n",
    "    # ─── 2) NUMERIC FEATURES WITH CORRELATION ─────────────────────────\n",
    "    numeric_cols = [\n",
    "        \"Amount\", \"Age\", \"Tenure\", \"MerchantRisk\", \"DeviceTrust\",\n",
    "        \"Txn24h\", \"Avg30d\", \"IPReputation\", \"Latitude\", \"Longitude\", \"DistFromHome\"\n",
    "    ]\n",
    "    # Random loadings from latent factors → numeric features\n",
    "    loadings = np.random.uniform(-1, 1, size=(n_latent, len(numeric_cols)))\n",
    "    # Build the numeric matrix\n",
    "    num_data = Z.dot(loadings) + np.random.normal(0, 0.5, size=(n_samples, len(numeric_cols)))\n",
    "\n",
    "    # Clip or transform to realistic ranges\n",
    "    df_num = pd.DataFrame(num_data, columns=numeric_cols)\n",
    "    df_num[\"Amount\"]    = np.exp(df_num[\"Amount\"] * 0.5 + 3.5)       # log-normal style\n",
    "    df_num[\"Age\"]       = np.clip(df_num[\"Age\"] * 5 + 40, 18, 90)\n",
    "    df_num[\"Tenure\"]    = np.abs(df_num[\"Tenure\"] * 10).astype(int)\n",
    "    df_num[\"Txn24h\"]    = np.abs(df_num[\"Txn24h\"].round()).astype(int)\n",
    "    df_num[\"Latitude\"]  = np.clip(37 + df_num[\"Latitude\"]*5, 25, 50)\n",
    "    df_num[\"Longitude\"] = np.clip(-95 + df_num[\"Longitude\"]*10, -125, -67)\n",
    "    # leave MerchantRisk, DeviceTrust, Avg30d, IPReputation, DistFromHome continuous\n",
    "\n",
    "    # ─── 3) CATEGORICAL FEATURES ───────────────────────────────────────\n",
    "    cats = {\n",
    "        \"TxType\":     ([\"purchase\",\"withdrawal\",\"transfer\",\"payment\"], [0.7,0.1,0.1,0.1]),\n",
    "        \"DeviceType\": ([\"mobile\",\"desktop\",\"ATM\",\"POS\",\"web\"],         [0.5,0.2,0.05,0.2,0.05]),\n",
    "        # give MerchantCat uniform probabilities so it's a tuple too\n",
    "        \"MerchantCat\":(\n",
    "            [\"grocery\",\"electronics\",\"travel\",\"entertainment\",\"gas\",\n",
    "             \"restaurant\",\"utilities\",\"clothing\"],\n",
    "            [1/8]*8\n",
    "        ),\n",
    "        \"Channel\":    ([\"online\",\"in-store\",\"contactless\",\"chip\"],      [0.4,0.4,0.1,0.1]),\n",
    "    }\n",
    "    df_cat = pd.DataFrame({\n",
    "        col: np.random.choice(domain, size=n_samples, p=probs)\n",
    "             if isinstance(probs, list)\n",
    "             else np.random.choice(domain, size=n_samples)\n",
    "        for col, (domain, probs) in cats.items()\n",
    "    })\n",
    "\n",
    "    # ─── 4) COMBINE & ADD TIME/CardPresent ────────────────────────────\n",
    "    raw = pd.concat([\n",
    "        pd.Series(times, name=\"Time\"),\n",
    "        df_num.reset_index(drop=True),\n",
    "        pd.Series(Hour, name=\"Hour\"),\n",
    "        df_cat,\n",
    "    ], axis=1)\n",
    "    raw[\"CardPresent\"] = (np.random.rand(n_samples) < 0.7).astype(int)\n",
    "\n",
    "    # ─── 5) RE-INTRODUCE MISSINGNESS ────────────────────────────────\n",
    "    missing_rates = {\n",
    "        \"Amount\": 0.01, \"Age\": 0.01, \"MerchantRisk\": 0.02, \"DeviceTrust\": 0.02,\n",
    "        \"Txn24h\": 0.01, \"Avg30d\": 0.01, \"IPReputation\": 0.02,\n",
    "        \"Latitude\": 0.005, \"Longitude\": 0.005, \"DistFromHome\": 0.01,\n",
    "        \"TxType\": 0.005, \"DeviceType\": 0.005, \"MerchantCat\": 0.01, \"Channel\": 0.005,\n",
    "    }\n",
    "    for col, rate in missing_rates.items():\n",
    "        mask = np.random.rand(n_samples) < rate\n",
    "        raw.loc[mask, col] = np.nan\n",
    "\n",
    "    # ─── 6) ADD MEASUREMENT NOISE ────────────────────────────────────\n",
    "    noise_cols = [\n",
    "        \"Amount\",\"Age\",\"MerchantRisk\",\"DeviceTrust\",\n",
    "        \"Txn24h\",\"Avg30d\",\"IPReputation\",\n",
    "        \"Latitude\",\"Longitude\",\"DistFromHome\"\n",
    "    ]\n",
    "    for c in noise_cols:\n",
    "        nonnull = raw[c].dropna()\n",
    "        if nonnull.empty:\n",
    "            continue\n",
    "        sigma = nonnull.std() * 0.02\n",
    "        raw.loc[raw[c].notna(), c] += np.random.normal(0, sigma, size=len(nonnull))\n",
    "\n",
    "\n",
    "    # ─── 5) SIMULATE FRAUD LABEL ON LATENT FACTORS ────────────────────\n",
    "    # Score driven mostly by latent factor 0 and factor 1\n",
    "    score = 0.8 * Z[:, 0] - 0.6 * Z[:, 1] + 1.2 * (raw[\"CardPresent\"] == 0)\n",
    "    prob  = 1 / (1 + np.exp(-score))\n",
    "    raw[\"Class\"] = (np.random.rand(n_samples) < prob).astype(int)\n",
    "\n",
    "    raw.to_csv(raw_out, index=False)\n",
    "    print(f\"• wrote raw → {raw_out}\")\n",
    "\n",
    "    # ─── 6) PCA TRANSFORM ─────────────────────────────────────────────\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    cat_mat = ohe.fit_transform(raw[list(cats.keys())].fillna(\"MISSING\"))\n",
    "    cat_cols = ohe.get_feature_names_out(list(cats.keys()))\n",
    "\n",
    "    num = raw.drop(columns=list(cats.keys()) + [\"Class\"])\n",
    "    num = num.fillna(num.mean())\n",
    "\n",
    "    features = pd.concat([\n",
    "        num.reset_index(drop=True),\n",
    "        pd.DataFrame(cat_mat, columns=cat_cols)\n",
    "    ], axis=1)\n",
    "\n",
    "    Xs = StandardScaler().fit_transform(features)\n",
    "    pca = PCA(n_components=28, random_state=random_state)\n",
    "    PCs = pca.fit_transform(Xs)\n",
    "\n",
    "    pca_df = pd.DataFrame(PCs, columns=[f\"V{i+1}\" for i in range(28)])\n",
    "    pca_df[\"Time\"]   = raw[\"Time\"].astype(int)\n",
    "    pca_df[\"Amount\"] = raw[\"Amount\"]\n",
    "    pca_df[\"Class\"]  = raw[\"Class\"]\n",
    "    pca_df.to_csv(pca_out, index=False)\n",
    "    print(f\"• wrote PCA → {pca_out}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_synthetic_demo(\n",
    "        n_samples=478_324,\n",
    "        raw_out=\"SYNTH_RAW_DATA.csv\",\n",
    "        pca_out=\"SYNTH_PCA_DATA.csv\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98062594-6df7-485e-a930-1c2cb90ba63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
